import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

iris = load_iris()
X = iris.data
y = iris.target
target_names = list(iris.target_names)
feature_names = iris.feature_names

X_std = StandardScaler().fit_transform(X)

pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_std)

print("Explained Variance Ratio:", pca.explained_variance_ratio_)
print(f"Total Variance Captured: {np.sum(pca.explained_variance_ratio_):.2f}")

plt.figure(figsize=(10, 7))
scatter = plt.scatter(
    X_pca[:, 0], X_pca[:, 1],
    c=y, cmap='viridis', s=70, edgecolor='k', marker='o'
)
plt.title("PCA - Dimensionality Reduction of Iris Dataset", fontsize=14)
plt.xlabel(f"Principal Component 1 ({pca.explained_variance_ratio_[0]*100:.2f}% variance)")
plt.ylabel(f"Principal Component 2 ({pca.explained_variance_ratio_[1]*100:.2f}% variance)")
plt.legend(handles=scatter.legend_elements()[0], labels=target_names, title="Iris Species")
plt.grid(True, linestyle='--', alpha=0.6)

for i, feature in enumerate(feature_names):
    plt.arrow(0, 0,
              pca.components_[0, i] * 3,
              pca.components_[1, i] * 3,
              color='r', alpha=0.7, head_width=0.05)
    plt.text(pca.components_[0, i] * 3.2,
             pca.components_[1, i] * 3.2,
             feature, color='r', ha='center', fontsize=9)

plt.show()
